# Awesome Human Video Generation [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of papers on human video generation, organized by driving signals.

## Table of Contents

- [Text-Driven Human Video Generation](#text-driven-human-video-generation)
- [Audio-Driven Human Video Generation](#audio-driven-human-video-generation)
- [Video-Driven Human Video Generation](#video-driven-human-video-generation)
- [Multimodality Driven Human Video Generation](#multimodality-driven-human-video-generation)

### Text-Driven Human Video Generation

- [Packing Input Frame Context in Next-Frame Prediction Models for Video Generation](https://arxiv.org/abs/2504.12626) (Apr., 2025) `Stanford University`<br>
  [![Star](https://img.shields.io/github/stars/lllyasviel/FramePack.svg?style=social&label=Star)](https://github.com/lllyasviel/FramePack) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2504.12626) [![Website](https://img.shields.io/badge/website-598BFF)](https://lllyasviel.github.io/frame_pack_gitpage/)

- [Wan: Open and Advanced Large-Scale Video Generative Models](https://arxiv.org/abs/2503.20314) (Mar., 2025) `Alibaba`<br>
  [![Star](https://img.shields.io/github/stars/Wan-Video/Wan2.1.svg?style=social&label=Star)](https://github.com/Wan-Video/Wan2.1) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.20314) [![Website](https://img.shields.io/badge/website-598BFF)](https://wan.video/)

- [Step-Video-TI2V Technical Report: A State-of-the-Art Text-Driven Image-to-Video Generation Model](https://arxiv.org/abs/2503.11251) (Mar., 2025) `StepFun`<br>
  [![Star](https://img.shields.io/github/stars/stepfun-ai/Step-Video-TI2V.svg?style=social&label=Star)](https://github.com/stepfun-ai/Step-Video-TI2V) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.11251)

- [HunyuanVideo: A Systematic Framework For Large Video Generation Model](https://arxiv.org/abs/2412.03603) (Dec., 2024) `Tencent`<br>
  [![Star](https://img.shields.io/github/stars/Tencent/HunyuanVideo.svg?style=social&label=Star)](https://github.com/Tencent/HunyuanVideo) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2412.03603) [![Website](https://img.shields.io/badge/website-598BFF)](https://aivideo.hunyuan.tencent.com/)

- [Make Pixels Dance: High-Dynamic Video Generation](https://arxiv.org/abs/2311.10982) (Nov., 2023) `ByteDance`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.10982) [![Website](https://img.shields.io/badge/website-598BFF)](https://makepixelsdance.github.io/)

- [Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets](https://arxiv.org/abs/2311.15127) (Nov., 2023) `Stability AI`<br>
  [![Star](https://img.shields.io/github/stars/Stability-AI/generative-models.svg?style=social&label=Star)](https://github.com/Stability-AI/generative-models) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.15127) [![Website](https://img.shields.io/badge/website-598BFF)](https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets)

- [ModelScope Text-to-Video Technical Report](https://arxiv.org/abs/2308.06571) (Aug., 2023) `Alibaba`<br>
  [![Star](https://img.shields.io/github/stars/modelscope/modelscope.svg?style=social&label=Star)](https://github.com/modelscope/modelscope) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2308.06571) [![Website](https://img.shields.io/badge/website-598BFF)](https://modelscope.cn/models/damo/text-to-video-synthesis/summary)

- [CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://arxiv.org/abs/2205.15868) (May, 2022) `Tsinghua`<br>
  [![Star](https://img.shields.io/github/stars/THUDM/CogVideo.svg?style=social&label=Star)](https://github.com/THUDM/CogVideo) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2205.15868)

### Audio-Driven Human Video Generation

- [EMO2: End-Effector Guided Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2501.10687) (Jan., 2025) `Alibaba`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2501.10687) [![Website](https://img.shields.io/badge/website-598BFF)](https://humanaigc.github.io/emote-portrait-alive-2/)

- [Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency](https://arxiv.org/abs/2409.02634) (Sep., 2024) `ByteDance`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2409.02634) [![Website](https://img.shields.io/badge/website-598BFF)](https://loopyavatar.github.io/)

- [EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model](https://arxiv.org/abs/2402.17485) (Feb., 2024) `Alibaba`<br>
  [![Star](https://img.shields.io/github/stars/HumanAIGC/EMO.svg?style=social&label=Star)](https://github.com/HumanAIGC/EMO) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2402.17485) [![Website](https://img.shields.io/badge/website-598BFF)](https://humanaigc.github.io/emote-portrait-alive/)

- [A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild](https://arxiv.org/abs/2008.10010) (Aug., 2020) `IIIT Hyderabad`<br>
  [![Star](https://img.shields.io/github/stars/Rudrabha/Wav2Lip.svg?style=social&label=Star)](https://github.com/Rudrabha/Wav2Lip) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2008.10010) [![Website](https://img.shields.io/badge/website-598BFF)](https://sync.so/)

### Video-Driven Human Video Generation

- [Animate Anyone 2: High-Fidelity Character Image Animation with Environment Affordance](https://arxiv.org/abs/2502.06145) (Feb., 2025) `Alibaba`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2502.06145) [![Website](https://img.shields.io/badge/website-598BFF)](https://humanaigc.github.io/animate-anyone-2/)

- [MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling](https://arxiv.org/abs/2409.16160) (Sep., 2024) `Tsinghua University`<br>
  [![Star](https://img.shields.io/github/stars/menyifang/MIMO.svg?style=social&label=Star)](https://github.com/menyifang/MIMO) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2409.16160) [![Website](https://img.shields.io/badge/website-598BFF)](https://menyifang.github.io/projects/MIMO/index.html)

- [UniAnimate: Taming Unified Video Diffusion Models for Consistent Human Image Animation](https://arxiv.org/abs/2406.01188) (Jun., 2024) `Alibaba`<br>
  [![Star](https://img.shields.io/github/stars/ali-vilab/UniAnimate.svg?style=social&label=Star)](https://github.com/ali-vilab/UniAnimate) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2406.01188) [![Website](https://img.shields.io/badge/website-598BFF)](https://unianimate.github.io/)

- [MimicMotion: High-Quality Human Motion Video Generation with Confidence-Aware Pose Guidance](https://arxiv.org/abs/2406.19680) (Jun., 2024) `Tencent`<br>
  [![Star](https://img.shields.io/github/stars/tencent/MimicMotion.svg?style=social&label=Star)](https://github.com/tencent/MimicMotion) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2406.19680) [![Website](https://img.shields.io/badge/website-598BFF)](https://tencent.github.io/MimicMotion/)

- [Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation](https://arxiv.org/abs/2406.01900) (Feb., 2024) `HKUST & Tencent`<br>
  [![Star](https://img.shields.io/github/stars/mayuelala/FollowYourEmoji.svg?style=social&label=Star)](https://github.com/mayuelala/FollowYourEmoji) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2406.01900) [![Website](https://img.shields.io/badge/website-598BFF)](https://follow-your-emoji.github.io/)

- [Talk-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model](https://arxiv.org/abs/2410.10696) (Feb., 2024) `Tsinghua University & Baidu`<br>
  [![Star](https://img.shields.io/github/stars/HumanAIGC/Talk-Act.svg?style=social&label=Star)](https://github.com/HumanAIGC/Talk-Act) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2410.10696) [![Website](https://img.shields.io/badge/website-598BFF)](https://guanjz20.github.io/projects/TALK-Act/)

- [Animate-X: Universal Character Image Animation with Enhanced Motion Representation](https://arxiv.org/abs/2410.10306) (Feb., 2024) `Ant Group & Alibaba`<br>
  [![Star](https://img.shields.io/github/stars/antgroup/animate-x.svg?style=social&label=Star)](https://github.com/antgroup/animate-x) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2410.10306) [![Website](https://img.shields.io/badge/website-598BFF)](https://lucaria-academy.github.io/Animate-X/)

- [CHAMP: Controllable and Consistent Human Image Animation with 3D Parametric Guidance](https://arxiv.org/abs/2403.14781) (Feb., 2024) `Nanjing University`<br>
  [![Star](https://img.shields.io/github/stars/fudan-generative-vision/champ.svg?style=social&label=Star)](https://github.com/fudan-generative-vision/champ) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2403.14781) [![Website](https://img.shields.io/badge/website-598BFF)](https://fudan-generative-vision.github.io/champ/#/)

- [Make-Your-Anchor: A Diffusion-Based 2D Avatar Generation Framework](https://arxiv.org/abs/2403.16510) (Feb., 2024) `Chinese Academy of Sciences`<br>
  [![Star](https://img.shields.io/github/stars/ICTMCG/Make-Your-Anchor.svg?style=social&label=Star)](https://github.com/ICTMCG/Make-Your-Anchor) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2403.16510)

- [MagicAnimate: Temporally Consistent Human Image Animation Using Diffusion Model](https://arxiv.org/abs/2311.16498) (Feb., 2024) `ByteDance`<br>
  [![Star](https://img.shields.io/github/stars/magic-research/magic-animate.svg?style=social&label=Star)](https://github.com/magic-research/magic-animate) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.16498) [![Website](https://img.shields.io/badge/website-598BFF)](https://showlab.github.io/magicanimate/)

- [Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation](https://arxiv.org/abs/2311.17117) (Nov., 2023) `Alibaba`<br>
  [![Star](https://img.shields.io/github/stars/HumanAIGC/AnimateAnyone.svg?style=social&label=Star)](https://github.com/HumanAIGC/AnimateAnyone) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.17117) [![Website](https://img.shields.io/badge/website-598BFF)](https://humanaigc.github.io/animate-anyone/)

- [MagicPose: Realistic Human Poses and Facial Expressions Retargeting with Identity-Aware Diffusion](https://arxiv.org/abs/2311.12052) (Nov., 2023) `University of Southern California & ByteDance`<br>
  [![Star](https://img.shields.io/github/stars/Boese0601/MagicDance.svg?style=social&label=Star)](https://github.com/Boese0601/MagicDance) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.12052) [![Website](https://img.shields.io/badge/website-598BFF)](https://humanaigc.github.io/magicpose/)

- [DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion](https://arxiv.org/abs/2304.06025) (Apr., 2023) `University of Washington`<br>
  [![Star](https://img.shields.io/github/stars/johannakarras/DreamPose.svg?style=social&label=Star)](https://github.com/johannakarras/DreamPose) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2304.06025) [![Website](https://img.shields.io/badge/website-598BFF)](https://grail.cs.washington.edu/projects/dreampose/)

- [DisCo: Disentangled Control for Realistic Human Dance Generation](https://arxiv.org/abs/2307.00040) (Feb., 2024) `Microsoft`<br>
  [![Star](https://img.shields.io/github/stars/Wangt-CN/DisCo.svg?style=social&label=Star)](https://github.com/Wangt-CN/DisCo) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2307.00040) [![Website](https://img.shields.io/badge/website-598BFF)](https://disco-dance.github.io/)

- [Thin-Plate Spline Motion Model for Image Animation](https://arxiv.org/abs/2203.14367) (Mar., 2022) `Tsinghua`<br>
  [![Star](https://img.shields.io/github/stars/yoyo-nb/Thin-Plate-Spline-Motion-Model.svg?style=social&label=Star)](https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2203.14367)

- [One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing](https://arxiv.org/abs/2011.15126) (Nov., 2021) `NVIDIA`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2011.15126) [![Website](https://img.shields.io/badge/website-598BFF)](https://nvlabs.github.io/face-vid2vid/)

- [PiRenderer: Controllable Portrait Image Generation via Semantic Neural Rendering](https://arxiv.org/abs/2109.08379) (Mar., 2021) `Peking University`<br>
  [![Star](https://img.shields.io/github/stars/RenYurui/PIRender.svg?style=social&label=Star)](https://github.com/RenYurui/PIRender) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2109.08379) [![Website](https://img.shields.io/badge/website-598BFF)](https://renyurui.github.io/PiRenderer/)

- [First Order Motion Model for Image Animation](https://arxiv.org/abs/2003.00196) (Mar., 2020) `University of Trento`<br>
  [![Star](https://img.shields.io/github/stars/AliaksandrSiarohin/first-order-model.svg?style=social&label=Star)](https://github.com/AliaksandrSiarohin/first-order-model) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2003.00196) [![Website](https://img.shields.io/badge/website-598BFF)](https://aliaksandrsiarohin.github.io/first-order-model-website/)

### Multimodality Driven Human Video Generation

- [DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance](https://arxiv.org/abs/2504.01724) (Apr., 2025) `ByteDance`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2504.01724) [![Website](https://img.shields.io/badge/website-598BFF)](https://grisoon.github.io/DreamActor-M1/)

- [OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models](https://arxiv.org/abs/2502.01061) (Feb., 2025) `ByteDance`<br>
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2502.01061) [![Website](https://img.shields.io/badge/website-598BFF)](https://omnihuman-lab.github.io/)

- [MotionGPT: Human Motion as a Foreign Language](https://arxiv.org/abs/2306.14795) (Jun., 2023) `Tencent`<br>
  [![Star](https://img.shields.io/github/stars/OpenMotionLab/MotionGPT.svg?style=social&label=Star)](https://github.com/OpenMotionLab/MotionGPT) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2306.14795) [![Website](https://img.shields.io/badge/website-598BFF)](https://motion-gpt.github.io/)